Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
align_reads              1
all                      1
annotate_variants        1
call_variants            1
index_bam                1
mark_duplicates          1
sort_bam                 1
total                    7

Select jobs to execute...

[Mon Jul  7 01:49:41 2025]
rule align_reads:
    input: results/raw/reference.fasta, results/raw/SRR1972739.fastq
    output: results/aligned/aligned.sam
    jobid: 5
    reason: Missing output files: results/aligned/aligned.sam; Updated input files: results/raw/reference.fasta, results/raw/SRR1972739.fastq
    resources: tmpdir=/tmp

[Mon Jul  7 01:49:42 2025]
Finished job 5.
1 of 7 steps (14%) done
Select jobs to execute...

[Mon Jul  7 01:49:42 2025]
rule sort_bam:
    input: results/aligned/aligned.sam
    output: results/aligned/aligned.sorted.bam
    jobid: 4
    reason: Input files updated by another job: results/aligned/aligned.sam
    resources: tmpdir=/tmp

[Mon Jul  7 01:49:42 2025]
Error in rule sort_bam:
    jobid: 4
    input: results/aligned/aligned.sam
    output: results/aligned/aligned.sorted.bam
    shell:
        samtools sort -o results/aligned/aligned.sorted.bam results/aligned/aligned.sam
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2025-07-07T014941.025592.snakemake.log
